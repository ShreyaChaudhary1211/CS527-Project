[<Line: +package org.mp4parser.streaming.input.h264;
>, <Line: +import org.mp4parser.boxes.iso14496.part12.SampleDescriptionBox;
>, <Line: +import org.mp4parser.boxes.iso14496.part15.AvcConfigurationBox;
>, <Line: +import org.mp4parser.boxes.sampleentry.VisualSampleEntry;
>, <Line: +import org.mp4parser.streaming.StreamingSample;
>, <Line: +import org.mp4parser.streaming.extensions.CompositionTimeSampleExtension;
>, <Line: +import org.mp4parser.streaming.extensions.CompositionTimeTrackExtension;
>, <Line: +import org.mp4parser.streaming.extensions.DimensionTrackExtension;
>, <Line: +import org.mp4parser.streaming.extensions.SampleFlagsSampleExtension;
>, <Line: +import org.mp4parser.streaming.input.StreamingSampleImpl;
>, <Line: +import org.mp4parser.streaming.input.h264.spspps.PictureParameterSet;
>, <Line: +import org.mp4parser.streaming.input.h264.spspps.SeqParameterSet;
>, <Line: +import org.mp4parser.streaming.input.h264.spspps.SliceHeader;
>, <Line: +import java.io.IOException;
>, <Line: +import java.nio.ByteBuffer;
>, <Line: +import java.util.ArrayList;
>, <Line: +import java.util.LinkedHashMap;
>, <Line: +import java.util.List;
>, <Line: +import java.util.concurrent.BlockingQueue;
>, <Line: +import java.util.concurrent.LinkedBlockingDeque;
>, <Line: +import java.util.concurrent.TimeUnit;
>, <Line: +import java.util.logging.Logger;
>, <Line: +public abstract class H264NalConsumingTrack extends AbstractH264Track {
>, <Line: +    private static final Logger LOG = Logger.getLogger(H264NalConsumingTrack.class.getName());
>, <Line: +    int max_dec_frame_buffering = 16;
>, <Line: +    List<StreamingSample> decFrameBuffer = new ArrayList<StreamingSample>();
>, <Line: +    List<StreamingSample> decFrameBuffer2 = new ArrayList<StreamingSample>();
>, <Line: +    LinkedHashMap<Integer, ByteBuffer> spsIdToSpsBytes = new LinkedHashMap<Integer, ByteBuffer>();
>, <Line: +    LinkedHashMap<Integer, SeqParameterSet> spsIdToSps = new LinkedHashMap<Integer, SeqParameterSet>();
>, <Line: +    LinkedHashMap<Integer, ByteBuffer> ppsIdToPpsBytes = new LinkedHashMap<Integer, ByteBuffer>();
>, <Line: +    LinkedHashMap<Integer, PictureParameterSet> ppsIdToPps = new LinkedHashMap<Integer, PictureParameterSet>();
>, <Line: +    BlockingQueue<SeqParameterSet> spsForConfig = new LinkedBlockingDeque<SeqParameterSet>();
>, <Line: +    int timescale = 0;
>, <Line: +    int frametick = 0;
>, <Line: +    boolean configured;
>, <Line: +    SampleDescriptionBox stsd;
>, <Line: +    SeqParameterSet currentSeqParameterSet = null;
>, <Line: +    PictureParameterSet currentPictureParameterSet = null;
>, <Line: +    List<ByteBuffer> buffered = new ArrayList<ByteBuffer>();
>, <Line: +    FirstVclNalDetector fvnd = null;
>, <Line: +    H264NalUnitHeader sliceNalUnitHeader;
>, <Line: +    public H264NalConsumingTrack() {
>, <Line: +    }
>, <Line: +    public static H264NalUnitHeader getNalUnitHeader(ByteBuffer nal) {
>, <Line: +        H264NalUnitHeader nalUnitHeader = new H264NalUnitHeader();
>, <Line: +        int type = nal.get(0);
>, <Line: +        nalUnitHeader.nal_ref_idc = (type >> 5) & 3;
>, <Line: +        nalUnitHeader.nal_unit_type = type & 0x1f;
>, <Line: +        return nalUnitHeader;
>, <Line: +    }
>, <Line: +    protected void consumeNal(ByteBuffer nal) throws IOException {
>, <Line: +        //LOG.finest("Consume NAL of " + nal.length + " bytes." + Hex.encodeHex(new byte[]{nal[0], nal[1], nal[2], nal[3], nal[4]}));
>, <Line: +        H264NalUnitHeader nalUnitHeader = getNalUnitHeader(nal);
>, <Line: +        switch (nalUnitHeader.nal_unit_type) {
>, <Line: +            case H264NalUnitTypes.CODED_SLICE_NON_IDR:
>, <Line: +            case H264NalUnitTypes.CODED_SLICE_DATA_PART_A:
>, <Line: +            case H264NalUnitTypes.CODED_SLICE_DATA_PART_B:
>, <Line: +            case H264NalUnitTypes.CODED_SLICE_DATA_PART_C:
>, <Line: +            case H264NalUnitTypes.CODED_SLICE_IDR:
>, <Line: +                FirstVclNalDetector current = new FirstVclNalDetector(nal,
>, <Line: +                        nalUnitHeader.nal_ref_idc, nalUnitHeader.nal_unit_type);
>, <Line: +                sliceNalUnitHeader = nalUnitHeader;
>, <Line: +                if (fvnd != null && fvnd.isFirstInNew(current)) {
>, <Line: +                    LOG.finer("Wrapping up cause of first vcl nal is found");
>, <Line: +                    pushSample(createSample(buffered, fvnd.sliceHeader, sliceNalUnitHeader), false, false);
>, <Line: +                    buffered.clear();
>, <Line: +                }
>, <Line: +                fvnd = current;
>, <Line: +                //System.err.println("" + nalUnitHeader.nal_unit_type);
>, <Line: +                buffered.add(nal);
>, <Line: +                //log.finer("NAL Unit Type: " + nalUnitHeader.nal_unit_type + " " + fvnd.frame_num);
>, <Line: +                break;
>, <Line: +            case H264NalUnitTypes.SEI:
>, <Line: +                if (fvnd != null) {
>, <Line: +                    LOG.finer("Wrapping up cause of SEI after vcl marks new sample");
>, <Line: +                    pushSample(createSample(buffered, fvnd.sliceHeader, sliceNalUnitHeader), false, false);
>, <Line: +                    buffered.clear();
>, <Line: +                    fvnd = null;
>, <Line: +                }
>, <Line: +                //System.err.println("" + nalUnitHeader.nal_unit_type);
>, <Line: +                buffered.add(nal);
>, <Line: +                break;
>, <Line: +            case H264NalUnitTypes.AU_UNIT_DELIMITER:
>, <Line: +                if (fvnd != null) {
>, <Line: +                    LOG.finer("Wrapping up cause of AU after vcl marks new sample");
>, <Line: +                    pushSample(createSample(buffered, fvnd.sliceHeader, sliceNalUnitHeader), false, false);
>, <Line: +                    buffered.clear();
>, <Line: +                    fvnd = null;
>, <Line: +                }
>, <Line: +                //System.err.println("" + nalUnitHeader.nal_unit_type);
>, <Line: +                buffered.add(nal);
>, <Line: +                break;
>, <Line: +            case H264NalUnitTypes.SEQ_PARAMETER_SET:
>, <Line: +                if (fvnd != null) {
>, <Line: +                    LOG.finer("Wrapping up cause of SPS after vcl marks new sample");
>, <Line: +                    pushSample(createSample(buffered, fvnd.sliceHeader, sliceNalUnitHeader), false, false);
>, <Line: +                    buffered.clear();
>, <Line: +                    fvnd = null;
>, <Line: +                }
>, <Line: +                handleSPS(nal);
>, <Line: +                break;
>, <Line: +            case 8:
>, <Line: +                if (fvnd != null) {
>, <Line: +                    LOG.finer("Wrapping up cause of PPS after vcl marks new sample");
>, <Line: +                    pushSample(createSample(buffered, fvnd.sliceHeader, sliceNalUnitHeader), false, false);
>, <Line: +                    buffered.clear();
>, <Line: +                    fvnd = null;
>, <Line: +                }
>, <Line: +                handlePPS(nal);
>, <Line: +                break;
>, <Line: +            case H264NalUnitTypes.END_OF_SEQUENCE:
>, <Line: +            case H264NalUnitTypes.END_OF_STREAM:
>, <Line: +                return;
>, <Line: +            case H264NalUnitTypes.SEQ_PARAMETER_SET_EXT:
>, <Line: +                throw new IOException("Sequence parameter set extension is not yet handled. Needs TLC.");
>, <Line: +            default:
>, <Line: +                //  buffered.add(nal);
>, <Line: +                LOG.warning("Unknown NAL unit type: " + nalUnitHeader.nal_unit_type);
>, <Line: +        }
>, <Line: +    }
>, <Line: +    protected void pushSample(StreamingSample ss, boolean all, boolean force) throws IOException {
>, <Line: +        if (ss != null) {
>, <Line: +            decFrameBuffer.add(ss);
>, <Line: +        }
>, <Line: +        if (all) {
>, <Line: +            while (decFrameBuffer.size() > 0) {
>, <Line: +                pushSample(null, false, true);
>, <Line: +            }
>, <Line: +        } else {
>, <Line: +            if ((decFrameBuffer.size() - 1 > max_dec_frame_buffering) || force) {
>, <Line: +                StreamingSample first = decFrameBuffer.remove(0);
>, <Line: +                PictureOrderCountType0SampleExtension poct0se = first.getSampleExtension(PictureOrderCountType0SampleExtension.class);
>, <Line: +                if (poct0se == null) {
>, <Line: +                    sampleSink.acceptSample(first, this);
>, <Line: +                } else {
>, <Line: +                    int delay = 0;
>, <Line: +                    for (StreamingSample streamingSample : decFrameBuffer) {
>, <Line: +                        if (poct0se.getPoc() > streamingSample.getSampleExtension(PictureOrderCountType0SampleExtension.class).getPoc()) {
>, <Line: +                            delay++;
>, <Line: +                        }
>, <Line: +                    }
>, <Line: +                    for (StreamingSample streamingSample : decFrameBuffer2) {
>, <Line: +                        if (poct0se.getPoc() < streamingSample.getSampleExtension(PictureOrderCountType0SampleExtension.class).getPoc()) {
>, <Line: +                            delay--;
>, <Line: +                        }
>, <Line: +                    }
>, <Line: +                    decFrameBuffer2.add(first);
>, <Line: +                    if (decFrameBuffer2.size() > max_dec_frame_buffering) {
>, <Line: +                        decFrameBuffer2.remove(0).removeSampleExtension(PictureOrderCountType0SampleExtension.class);
>, <Line: +                    }
>, <Line: +                    first.addSampleExtension(CompositionTimeSampleExtension.create(delay * frametick));
>, <Line: +                    //System.err.println("Adding sample");
>, <Line: +                    sampleSink.acceptSample(first, this);
>, <Line: +                }
>, <Line: +            }
>, <Line: +        }
>, <Line: +    }
>, <Line: +    protected SampleFlagsSampleExtension createSampleFlagsSampleExtension(H264NalUnitHeader nu, SliceHeader sliceHeader) {
>, <Line: +        SampleFlagsSampleExtension sampleFlagsSampleExtension = new SampleFlagsSampleExtension();
>, <Line: +        if (nu.nal_ref_idc == 0) {
>, <Line: +            sampleFlagsSampleExtension.setSampleIsDependedOn(2);
>, <Line: +        } else {
>, <Line: +            sampleFlagsSampleExtension.setSampleIsDependedOn(1);
>, <Line: +        }
>, <Line: +        if ((sliceHeader.slice_type == SliceHeader.SliceType.I) || (sliceHeader.slice_type == SliceHeader.SliceType.SI)) {
>, <Line: +            sampleFlagsSampleExtension.setSampleDependsOn(2);
>, <Line: +        } else {
>, <Line: +            sampleFlagsSampleExtension.setSampleDependsOn(1);
>, <Line: +        }
>, <Line: +        sampleFlagsSampleExtension.setSampleIsNonSyncSample(H264NalUnitTypes.CODED_SLICE_IDR != nu.nal_unit_type);
>, <Line: +        return sampleFlagsSampleExtension;
>, <Line: +    }
>, <Line: +    protected PictureOrderCountType0SampleExtension createPictureOrderCountType0SampleExtension(SliceHeader sliceHeader) {
>, <Line: +        if (sliceHeader.sps.pic_order_cnt_type == 0) {
>, <Line: +            return new PictureOrderCountType0SampleExtension(
>, <Line: +                    sliceHeader, decFrameBuffer.size() > 0 ?
>, <Line: +                    decFrameBuffer.get(decFrameBuffer.size() - 1).getSampleExtension(PictureOrderCountType0SampleExtension.class) :
>, <Line: +                    null);
>, <Line: +/*            decFrameBuffer.add(ssi);
>, <Line: +            if (decFrameBuffer.size() - 1 > max_dec_frame_buffering) { // just added one
>, <Line: +                drainDecPictureBuffer(false);
>, <Line: +            }*/
>, <Line: +        } else if (sliceHeader.sps.pic_order_cnt_type == 1) {
>, <Line: +            throw new RuntimeException("pic_order_cnt_type == 1 needs to be implemented");
>, <Line: +        } else if (sliceHeader.sps.pic_order_cnt_type == 2) {
>, <Line: +            return null; // no ctts
>, <Line: +        }
>, <Line: +        throw new RuntimeException("I don't know sliceHeader.sps.pic_order_cnt_type of " + sliceHeader.sps.pic_order_cnt_type);
>, <Line: +    }
>, <Line: +    protected StreamingSample createSample(List<ByteBuffer> nals, SliceHeader sliceHeader, H264NalUnitHeader nu) throws IOException {
>, <Line: +        LOG.finer("Create Sample");
>, <Line: +        configure();
>, <Line: +        if (timescale == 0 || frametick == 0) {
>, <Line: +            throw new IOException("Frame Rate needs to be configured either by hand or by SPS before samples can be created");
>, <Line: +        }
>, <Line: +        StreamingSample ss = new StreamingSampleImpl(
>, <Line: +                nals,
>, <Line: +                frametick);
>, <Line: +        ss.addSampleExtension(createSampleFlagsSampleExtension(nu, sliceHeader));
>, <Line: +        ss.addSampleExtension(createPictureOrderCountType0SampleExtension(sliceHeader));
>, <Line: +        return ss;
>, <Line: +    }
>, <Line: +    public void setFrametick(int frametick) {
>, <Line: +        this.frametick = frametick;
>, <Line: +    }
>, <Line: +    public synchronized void configure() {
>, <Line: +        if (!configured) {
>, <Line: +            SeqParameterSet sps;
>, <Line: +            try {
>, <Line: +                sps = spsForConfig.poll(5L, TimeUnit.SECONDS);
>, <Line: +                if (sps == null) {
>, <Line: +                    LOG.warning("Can't determine frame rate as no SPS became available in time");
>, <Line: +                    return;
>, <Line: +                }
>, <Line: +            } catch (InterruptedException e) {
>, <Line: +                LOG.warning(e.getMessage());
>, <Line: +                LOG.warning("Can't determine frame rate as no SPS became available in time");
>, <Line: +                return;
>, <Line: +            }
>, <Line: +            if (sps.pic_order_cnt_type == 0 || sps.pic_order_cnt_type == 1) {
>, <Line: +                this.addTrackExtension(new CompositionTimeTrackExtension());
>, <Line: +            }
>, <Line: +            int width = (sps.pic_width_in_mbs_minus1 + 1) * 16;
>, <Line: +            int mult = 2;
>, <Line: +            if (sps.frame_mbs_only_flag) {
>, <Line: +                mult = 1;
>, <Line: +            }
>, <Line: +            int height = 16 * (sps.pic_height_in_map_units_minus1 + 1) * mult;
>, <Line: +            if (sps.frame_cropping_flag) {
>, <Line: +                int chromaArrayType = 0;
>, <Line: +                if (!sps.residual_color_transform_flag) {
>, <Line: +                    chromaArrayType = sps.chroma_format_idc.getId();
>, <Line: +                }
>, <Line: +                int cropUnitX = 1;
>, <Line: +                int cropUnitY = mult;
>, <Line: +                if (chromaArrayType != 0) {
>, <Line: +                    cropUnitX = sps.chroma_format_idc.getSubWidth();
>, <Line: +                    cropUnitY = sps.chroma_format_idc.getSubHeight() * mult;
>, <Line: +                }
>, <Line: +                width -= cropUnitX * (sps.frame_crop_left_offset + sps.frame_crop_right_offset);
>, <Line: +                height -= cropUnitY * (sps.frame_crop_top_offset + sps.frame_crop_bottom_offset);
>, <Line: +            }
>, <Line: +            VisualSampleEntry visualSampleEntry = new VisualSampleEntry("avc1");
>, <Line: +            visualSampleEntry.setDataReferenceIndex(1);
>, <Line: +            visualSampleEntry.setDepth(24);
>, <Line: +            visualSampleEntry.setFrameCount(1);
>, <Line: +            visualSampleEntry.setHorizresolution(72);
>, <Line: +            visualSampleEntry.setVertresolution(72);
>, <Line: +            DimensionTrackExtension dte = this.getTrackExtension(DimensionTrackExtension.class);
>, <Line: +            if (dte == null) {
>, <Line: +                this.addTrackExtension(new DimensionTrackExtension(width, height));
>, <Line: +            }
>, <Line: +            visualSampleEntry.setWidth(width);
>, <Line: +            visualSampleEntry.setHeight(height);
>, <Line: +            visualSampleEntry.setCompressorname("AVC Coding");
>, <Line: +            AvcConfigurationBox avcConfigurationBox = new AvcConfigurationBox();
>, <Line: +            avcConfigurationBox.setSequenceParameterSets(new ArrayList<ByteBuffer>(spsIdToSpsBytes.values()));
>, <Line: +            avcConfigurationBox.setPictureParameterSets(new ArrayList<ByteBuffer>(ppsIdToPpsBytes.values()));
>, <Line: +            avcConfigurationBox.setAvcLevelIndication(sps.level_idc);
>, <Line: +            avcConfigurationBox.setAvcProfileIndication(sps.profile_idc);
>, <Line: +            avcConfigurationBox.setBitDepthLumaMinus8(sps.bit_depth_luma_minus8);
>, <Line: +            avcConfigurationBox.setBitDepthChromaMinus8(sps.bit_depth_chroma_minus8);
>, <Line: +            avcConfigurationBox.setChromaFormat(sps.chroma_format_idc.getId());
>, <Line: +            avcConfigurationBox.setConfigurationVersion(1);
>, <Line: +            avcConfigurationBox.setLengthSizeMinusOne(3);
>, <Line: +            avcConfigurationBox.setProfileCompatibility(
>, <Line: +                    (sps.constraint_set_0_flag ? 128 : 0) +
>, <Line: +                            (sps.constraint_set_1_flag ? 64 : 0) +
>, <Line: +                            (sps.constraint_set_2_flag ? 32 : 0) +
>, <Line: +                            (sps.constraint_set_3_flag ? 16 : 0) +
>, <Line: +                            (sps.constraint_set_4_flag ? 8 : 0) +
>, <Line: +                            (int) (sps.reserved_zero_2bits & 0x3)
>, <Line: +            );
>, <Line: +            visualSampleEntry.addBox(avcConfigurationBox);
>, <Line: +            stsd = new SampleDescriptionBox();
>, <Line: +            stsd.addBox(visualSampleEntry);
>, <Line: +            int _timescale;
>, <Line: +            int _frametick;
>, <Line: +            if (sps.vuiParams != null) {
>, <Line: +                _timescale = sps.vuiParams.time_scale >> 1; // Not sure why, but I found this in several places, and it works...
>, <Line: +                _frametick = sps.vuiParams.num_units_in_tick;
>, <Line: +                if (_timescale == 0 || _frametick == 0) {
>, <Line: +                    LOG.warning("vuiParams contain invalid values: time_scale: " + _timescale + " and frame_tick: " + _frametick + ". Setting frame rate to 25fps");
>, <Line: +                    _timescale = 0;
>, <Line: +                    _frametick = 0;
>, <Line: +                }
>, <Line: +                if (_frametick > 0) {
>, <Line: +                    if (_timescale / _frametick > 100) {
>, <Line: +                        LOG.warning("Framerate is " + (_timescale / _frametick) + ". That is suspicious.");
>, <Line: +                    }
>, <Line: +                } else {
>, <Line: +                    LOG.warning("Frametick is " + _frametick + ". That is suspicious.");
>, <Line: +                }
>, <Line: +                if (sps.vuiParams.bitstreamRestriction != null) {
>, <Line: +                    max_dec_frame_buffering = sps.vuiParams.bitstreamRestriction.max_dec_frame_buffering;
>, <Line: +                }
>, <Line: +            } else {
>, <Line: +                LOG.warning("Can't determine frame rate as SPS does not contain vuiParama");
>, <Line: +                _timescale = 0;
>, <Line: +                _frametick = 0;
>, <Line: +            }
>, <Line: +            if (timescale == 0) {
>, <Line: +                timescale = _timescale;
>, <Line: +            }
>, <Line: +            if (frametick == 0) {
>, <Line: +                frametick = _frametick;
>, <Line: +            }
>, <Line: +            if (sps.pic_order_cnt_type == 0) {
>, <Line: +                this.addTrackExtension(new CompositionTimeTrackExtension());
>, <Line: +            } else if (sps.pic_order_cnt_type == 1) {
>, <Line: +                throw new RuntimeException("Have not yet imlemented pic_order_cnt_type 1");
>, <Line: +            }
>, <Line: +            configured = true;
>, <Line: +        }
>, <Line: +    }
>, <Line: +    public long getTimescale() {
>, <Line: +        configure();
>, <Line: +        return timescale;
>, <Line: +    }
>, <Line: +    public void setTimescale(int timescale) {
>, <Line: +        this.timescale = timescale;
>, <Line: +    }
>, <Line: +    public SampleDescriptionBox getSampleDescriptionBox() {
>, <Line: +        configure();
>, <Line: +        return stsd;
>, <Line: +    }
>, <Line: +    public String getHandler() {
>, <Line: +        return "vide";
>, <Line: +    }
>, <Line: +    public String getLanguage() {
>, <Line: +        return "eng";
>, <Line: +    }
>, <Line: +    protected void handlePPS(ByteBuffer nal) {
>, <Line: +        nal.position(1);
>, <Line: +        PictureParameterSet _pictureParameterSet = null;
>, <Line: +        try {
>, <Line: +            _pictureParameterSet = PictureParameterSet.read(nal);
>, <Line: +            currentPictureParameterSet = _pictureParameterSet;
>, <Line: +            ByteBuffer oldPpsSameId = ppsIdToPpsBytes.get(_pictureParameterSet.pic_parameter_set_id);
>, <Line: +            if (oldPpsSameId != null && !oldPpsSameId.equals(nal)) {
>, <Line: +                throw new RuntimeException("OMG - I got two SPS with same ID but different settings! (AVC3 is the solution)");
>, <Line: +            } else {
>, <Line: +                ppsIdToPpsBytes.put(_pictureParameterSet.pic_parameter_set_id, nal);
>, <Line: +                ppsIdToPps.put(_pictureParameterSet.pic_parameter_set_id, _pictureParameterSet);
>, <Line: +            }
>, <Line: +        } catch (IOException e) {
>, <Line: +            throw new RuntimeException("That's surprising to get IOException when working on ByteArrayInputStream", e);
>, <Line: +        }
>, <Line: +    }
>, <Line: +    protected void handleSPS(ByteBuffer data) {
>, <Line: +        data.position(1);
>, <Line: +        try {
>, <Line: +            SeqParameterSet _seqParameterSet = SeqParameterSet.read(data);
>, <Line: +            currentSeqParameterSet = _seqParameterSet;
>, <Line: +            ByteBuffer oldSpsSameId = spsIdToSpsBytes.get(_seqParameterSet.seq_parameter_set_id);
>, <Line: +            if (oldSpsSameId != null && !oldSpsSameId.equals(data)) {
>, <Line: +                throw new RuntimeException("OMG - I got two SPS with same ID but different settings!");
>, <Line: +            } else {
>, <Line: +                spsIdToSpsBytes.put(_seqParameterSet.seq_parameter_set_id, data);
>, <Line: +                spsIdToSps.put(_seqParameterSet.seq_parameter_set_id, _seqParameterSet);
>, <Line: +                spsForConfig.add(_seqParameterSet);
>, <Line: +            }
>, <Line: +        } catch (IOException e) {
>, <Line: +            throw new RuntimeException("That's surprising to get IOException when working on ByteArrayInputStream", e);
>, <Line: +        }
>, <Line: +    }
>, <Line: +    public void close() throws IOException {
>, <Line: +    }
>, <Line: +    class FirstVclNalDetector {
>, <Line: +        public final SliceHeader sliceHeader;
>, <Line: +        int frame_num;
>, <Line: +        int pic_parameter_set_id;
>, <Line: +        boolean field_pic_flag;
>, <Line: +        boolean bottom_field_flag;
>, <Line: +        int nal_ref_idc;
>, <Line: +        int pic_order_cnt_type;
>, <Line: +        int delta_pic_order_cnt_bottom;
>, <Line: +        int pic_order_cnt_lsb;
>, <Line: +        int delta_pic_order_cnt_0;
>, <Line: +        int delta_pic_order_cnt_1;
>, <Line: +        boolean idrPicFlag;
>, <Line: +        int idr_pic_id;
>, <Line: +        public FirstVclNalDetector(ByteBuffer nal, int nal_ref_idc, int nal_unit_type) {
>, <Line: +            SliceHeader sh = new SliceHeader(nal, spsIdToSps, ppsIdToPps, nal_unit_type == 5);
>, <Line: +            this.sliceHeader = sh;
>, <Line: +            this.frame_num = sh.frame_num;
>, <Line: +            this.pic_parameter_set_id = sh.pic_parameter_set_id;
>, <Line: +            this.field_pic_flag = sh.field_pic_flag;
>, <Line: +            this.bottom_field_flag = sh.bottom_field_flag;
>, <Line: +            this.nal_ref_idc = nal_ref_idc;
>, <Line: +            this.pic_order_cnt_type = spsIdToSps.get(ppsIdToPps.get(sh.pic_parameter_set_id).seq_parameter_set_id).pic_order_cnt_type;
>, <Line: +            this.delta_pic_order_cnt_bottom = sh.delta_pic_order_cnt_bottom;
>, <Line: +            this.pic_order_cnt_lsb = sh.pic_order_cnt_lsb;
>, <Line: +            this.delta_pic_order_cnt_0 = sh.delta_pic_order_cnt_0;
>, <Line: +            this.delta_pic_order_cnt_1 = sh.delta_pic_order_cnt_1;
>, <Line: +            this.idr_pic_id = sh.idr_pic_id;
>, <Line: +        }
>, <Line: +        boolean isFirstInNew(FirstVclNalDetector nu) {
>, <Line: +            if (nu.frame_num != frame_num) {
>, <Line: +                return true;
>, <Line: +            }
>, <Line: +            if (nu.pic_parameter_set_id != pic_parameter_set_id) {
>, <Line: +                return true;
>, <Line: +            }
>, <Line: +            if (nu.field_pic_flag != field_pic_flag) {
>, <Line: +                return true;
>, <Line: +            }
>, <Line: +            if (nu.field_pic_flag) {
>, <Line: +                if (nu.bottom_field_flag != bottom_field_flag) {
>, <Line: +                    return true;
>, <Line: +                }
>, <Line: +            }
>, <Line: +            if (nu.nal_ref_idc != nal_ref_idc) {
>, <Line: +                return true;
>, <Line: +            }
>, <Line: +            if (nu.pic_order_cnt_type == 0 && pic_order_cnt_type == 0) {
>, <Line: +                if (nu.pic_order_cnt_lsb != pic_order_cnt_lsb) {
>, <Line: +                    return true;
>, <Line: +                }
>, <Line: +                if (nu.delta_pic_order_cnt_bottom != delta_pic_order_cnt_bottom) {
>, <Line: +                    return true;
>, <Line: +                }
>, <Line: +            }
>, <Line: +            if (nu.pic_order_cnt_type == 1 && pic_order_cnt_type == 1) {
>, <Line: +                if (nu.delta_pic_order_cnt_0 != delta_pic_order_cnt_0) {
>, <Line: +                    return true;
>, <Line: +                }
>, <Line: +                if (nu.delta_pic_order_cnt_1 != delta_pic_order_cnt_1) {
>, <Line: +                    return true;
>, <Line: +                }
>, <Line: +            }
>, <Line: +            if (nu.idrPicFlag != idrPicFlag) {
>, <Line: +                return true;
>, <Line: +            }
>, <Line: +            if (nu.idrPicFlag && idrPicFlag) {
>, <Line: +                if (nu.idr_pic_id != idr_pic_id) {
>, <Line: +                    return true;
>, <Line: +                }
>, <Line: +            }
>, <Line: +            return false;
>, <Line: +        }
>, <Line: +    }
>, <Line: +}
>]
[]